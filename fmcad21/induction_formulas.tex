% !TeX root = ./paper.tex

There are many ways to generate induction formulas \cite{aclhandbook,bundychapter,cruanes,hipspec,hipster,isaplanner,computing}. In this section, we utilise function and predicate definitions to come up with them. Given an $n$-ary function $\mathtt{f}$, we define its induction template based on its function definition axioms. Each axiom $\mathcal{C}:=C\lor \mathtt{f}(\overline{s}) \rightsquigarrow t$ defines a set of recursive calls:
$$\mathcal{R}(\mathcal{C}):=\{\mathtt{f}(\overline{s^\prime})\mid \mathtt{f}(\overline{s^\prime})\trianglelefteq t\}$$
\todo[inline]{define how to merge these sets}
We categorize argument positions $1\le i\le n$ based on \cite{cruanes}. An argument position is \textit{active} if there is an axiom $\mathcal{C}$ for $\mathtt{f}$ s.t. $s_i \trianglerighteq s^\prime_i$ for some $\mathtt{f}(\overline{s^\prime})\in\mathcal{R}(\mathcal{C})$. An argument position is \textit{accumulator} if $s_i$ is a variable and $s_i\neq s^\prime_i$. We denote the active argument positions of $\mathtt{f}$ with $I_\mathtt{f}$.

\todo[inline]{Here is a big gap: we have to differentiate between active arguments, "accumulators" that are needed for the correct strengthening of hypothesis, passive one that are not variables and simply passive arguments. This is not done in the implementation either.}

Given a function term $\mathtt{f}(\overline{c})$, we define a case distinction over the terms $\{c_i\mid I_\mathtt{f}\}$ as follows: we create a new term $\mathtt{f}(\overline{c^\prime})$ where we replace each $c_i$ with $i\in I_\mathtt{f}$ with fresh variables. We then take every axiom $\mathcal{C}:=C\lor \mathtt{f}(\overline{s}) \rightsquigarrow t$ of $\mathtt{f}$. Let us define the unification of $\mathtt{f}(\overline{s})$ and $\mathtt{f}(\overline{c^\prime})$ with mgu $\theta$ as $f(\overline{t})=f(\overline{s})\theta=f(\overline{c^\prime})\theta$. If this term exists, we create a mapping $\{c_i\mapsto t_i\mid i\in I_\mathtt{f}\}$. This tells what terms to substitute for the induction terms in this case of the induction formula.

We create similar mappings unifying each $\mathtt{f}(\overline{s^\prime})\theta\in\mathcal{R}(\mathcal{C})$ with $\mathtt{f}(\overline{c^\prime})$.

\begin{example}\label{ex:3}
	Given the function definition:
	\begin{equation}
	\begin{aligned}
	\nonumber
	&\textbf{fun } \qreva (x : \lst, y : \lst) \rightarrow \lst :=\\
	&\tab\textbf{match } x \textbf{ with}\\
	&\tab\tab(\nil\rightarrow y)\\ &\tab\tab(\cons(u,v)\rightarrow\qreva(v,\cons(u,y))\end{aligned}\end{equation}
	And the unit clause:
	$$\qreva(\sigma_0,\sigma_1)\neq\append(\rev(\sigma_0),\sigma_1)$$
	Let us first look at the function term $\qreva(\sigma_0,\sigma_1)$:
	We create the term with variables $\qreva(x,\sigma_1)$. Then, we unify with each
	header and recursive call of $\qreva$:
	\begin{enumerate}
		\item $\qreva(x,\sigma_1)$ unified with $\qreva(\nil,y)$ gives the mapping $\{\sigma_0\mapsto\nil\}$.
		\item $\qreva(x,\sigma_1)$ unified with $\qreva(\cons(u,v),y)$ gives $\{\sigma_0\mapsto\cons(u,v)\}$
		\item On the recursive call, first we apply the unifier in the header: $\qreva(v, \cons(u,\sigma_1))$. The mapping for the corresponding hypothesis is $\{\sigma_0\mapsto v\}$
	\end{enumerate}
	We use the mappings to create a corresponding induction formula: each mapping defines what to replace:
	$$\begin{pmatrix}
	\qreva(\nil,\sigma_1)=\append(\rev(\nil),\sigma_1)\land\\
	\forall u,v.\begin{pmatrix}\qreva(v,\sigma_1)=\append(\rev(v),\sigma_1)\rightarrow\\
	\qreva(\cons(u,v),\sigma_1)=\append(\rev(\cons(u,v)),\sigma_1)\end{pmatrix}
	\end{pmatrix}\rightarrow...$$
\end{example}

The above method -- when used on each predicate and function term in a literal -- gives "matching" induction formulas in a sense that in each case of an induction formula by definition at least the term this formula was generated from will be an instance of the corresponding function/predicate definition.

The method can be improved in two regards: first, we can recursively mark terms in a literal in active positions and only generate formulas from those, since all others will get stuck at some point. Second, we can create terms to generate from based on subterms in active arguments.

For example the following literal contains two terms that can generate induction formulas:
$$\neg\fleq(\sigma_0,\add(\sigma_1,\sigma_0))$$
The first one gives induction terms $\sigma_0$ and $\add(\sigma_1,\sigma_0)$, the second $\sigma_1$, whereas we need one where we induct on $\sigma_0$ and $\sigma_1$ simultaneously, to match the recursive case of $\fleq$ after simplifying with $\add$. But when looking at the $\fleq$ term, instead of only taking the $\add$ term as the second argument, we look inside its active arguments and take $\sigma_1$ also (essentially generating from term $\fleq(\sigma_0, \sigma_1)$).

More generally, when considering a term $\mathtt{f}(t_1,...,t_n)$, we take all subterms in its active argument positions $t_i$ with the same sort as $t_i$, and take all combinations (leaving non-active arguments).
\subsection{Strengthening the hypotheses}
In Example \ref{ex:3}, after clausification and rewriting with function definitions, the base case is solved, but we are left with the following two unit clauses (the step case conclusion and hypothesis):
$$\qreva(\sigma_2,\sigma_1)=\append(\rev(\sigma_2),\sigma_1)$$
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))\neq\append(\append(\rev(\sigma_2),\cons(\sigma_3,\nil)),\sigma_1)$$
An easy solution for this is to use a \textit{strengthened hypothesis}, where we replace $\sigma_1$ with a universally quantified variable, so that the left-hand sides will match:
$$\qreva(\sigma_2,z)=\append(\rev(\sigma_2),z)$$
Yet, this "too strong" hypothesis can backfire in many ways: not only does it burden the solver by more potential rewrites but the prover may even demodulate the wrong side of the step conclusion after which the proof is ultimately stuck:
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))\neq\append(\qreva(\sigma_2,\cons(\sigma_3,\nil),\sigma_1))$$
Our proposed solution is to use accumulator argument positions to gives us hints at possible non-trivial hypotheses. In Example \ref{ex:3}, unifying with the recursive call gives $\qreva(v, \cons(u,\sigma_1))$, which means we can replace $\sigma_1$ -- after Skolemizing $\cons(u,\sigma_1)$ -- with $\cons(\sigma_3,\sigma_1)$:
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))=\append(\rev(\sigma_2),\cons(\sigma_3,\sigma_1))$$
The left-hand sides now match exactly, so applying the hypothesis gives:
$$\append(\rev(\sigma_2),\cons(\sigma_3,\sigma_1))\neq\append(\append(\rev(\sigma_2),\cons(\sigma_3,\nil)),\sigma_1)$$

\subsection{Generalizations}
As described in \cite{vampiregeneralization}, inducting on all occurrences of an induction term may lead to a failed proof even if the case distinction was the right one. Inspired by \cite{cruanes}, we devised a heuristic that takes \textit{all active occurrences} of an induction term. So for example, we generalize the literal $\forall x.\fleq(x,\add(x,x))$ to $\forall x,z.\fleq(z,\add(z,x))$.

But sometimes, e.g. in $\forall x.\double(x) = \add(x,x)$, we have to take all occurrences including the last, non-active one. We therefore, instead of trying to guess the right one, try both active and all occurrences. So we generalize to $\forall x,z.\double(z) = \add(z,x)$ and $\forall z.\double(z) = \add(z,z)$ as well.

