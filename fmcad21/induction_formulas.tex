% !TeX root = ./paper.tex

There are many ways to generate induction formulas \cite{aclhandbook,bundychapter,cruanes,hipspec,hipster,isaplanner,computing}. In this section, we utilise function and predicate definitions to come up with them. A function or predicate has a number of branches, these are characterized by one or more clauses.  Two clauses $C\lor \mathtt{f}(\overline{s_1})\rightsquigarrow t_1$ and $D\lor \mathtt{f}(\overline{s_2})\rightsquigarrow t_2$ belong to the same branch of a function $\mathtt{f}$ if $\mathtt{f}(\overline{s_1})$ and $\mathtt{f}(\overline{s_2})$ are variants of each other. Similarly, two clauses $C\lor (\neg)\mathtt{P}(\overline{s_1})$ and $D\lor (\neg)\mathtt{P}(\overline{s_2})$ belong to the same branch of a predicate $\mathtt{P}$ if $\mathtt{P}(\overline{s_1})$ and $\mathtt{P}(\overline{s_2})$ are variants of each other. Therefore, we can characterize a branch with its characteristic term $\mathtt{f}(\overline{s})$ or atom $\mathtt{P}(\overline{t})$.

For a function, the recursive calls corresponding to one of its branches $\mathtt{f}(\overline{s})$ is the set:
$$\mathcal{R}(\mathtt{f}(\overline{s})):=\{\mathtt{f}(\overline{s^\prime})\mid \mathtt{f}(\overline{s^\prime})\trianglelefteq t, C\lor \mathtt{f}(\overline{s}) \rightsquigarrow t\}$$

For a predicate branch $\mathtt{P}(\overline{t})$, the set is:
$$\mathcal{R}(\mathtt{P}(\overline{t})):=\{\mathtt{P}(\overline{s^\prime})\in C, \mathtt{P}(\overline{t})
\lor C\}$$

\todo[inline]{Argue why we are not taking guard conditions into account when generating an induction formula. The reason is more or less that after rewriting a literal stemming from induction $L[f(c(\sigma))]\lor C$ with all corresponding function definitions $f(c(x))\lor C_1$, ..., $f(c(x))\lor C_n$, we get $n$ clauses which -- given the functions are well-defined -- can be binary resolved against each other in the end. Also, due to well-definedness, there cannot be any function definition that we can demodulate (or subsumption demodulate) with, so this always results in the $n$ branches being expanded (except when $C$ already contains the matching condition from one $C_i$ but then by well-definedness, the others would be unnecessary)}

We categorize argument positions $1\le i\le n$ based on \cite{cruanes}. An argument position for function $\mathtt{f}$ is \textit{active} if there is a branch characterized by $\mathtt{f}(\overline{s})$ s.t. $s_i \trianglerighteq s^\prime_i$ for some $\mathtt{f}(\overline{s^\prime})\in\mathcal{R}(\mathtt{f}(\overline{s}))$. An argument position is \textit{accumulator} if $s_i$ is a variable and $s_i\neq s^\prime_i$. We denote the active argument positions of $\mathtt{f}$ with $I_\mathtt{f}$.

Given a function term $\mathtt{f}(\overline{c})$, we define a case distinction over the terms $\{c_i\mid i\in I_\mathtt{f}\}$ as follows: we create a new term $\mathtt{f}(\overline{c^\prime})$ where we replace each $c_i$ with $i\in I_\mathtt{f}$ with fresh variables. Let $\theta$ be the mgu for each branch characterized by $\mathtt{f}(\overline{s})$ and $\mathtt{f}(\overline{c})$ and let $\mathtt{f}(\overline{t}):=\mathtt{f}(\overline{s})\theta=\mathtt{f}(\overline{c^\prime})\theta$. If the two terms can be unified, we create a mapping $\{c_i\mapsto t_i\mid i\in I_\mathtt{f}\}$. This tells what terms to substitute for the induction terms in this case of the induction formula. Then, we create the mappings for the induction hypotheses corresponding to this case: we take each $\mathtt{f}(\overline{s^\prime})\theta\in\mathcal{R}(\mathtt{f}(\overline{s}))$, and unify them with $\mathtt{f}(\overline{c^\prime})$. The unifications, if they exist, give rise to similar mappings.

\begin{example}\label{ex:3}
	Given the function definition $\qreva : (\lst, \lst)\rightarrow\lst$:
	\begin{align}
	&\qreva(\nil)\rightsquigarrow y\label{qreva1}\tag{qreva.1}\\ &\qreva(\cons(u,v))\rightsquigarrow\qreva(v,\cons(u,y))\label{qreva2}\tag{qreva.2}\end{align}
	And the unit clause:
	$$\qreva(\sigma_0,\sigma_1)\neq\append(\rev(\sigma_0),\sigma_1)$$
	Let us first look at the function term $\qreva(\sigma_0,\sigma_1)$:
	We create the term with variables $\qreva(x,\sigma_1)$. Then, we unify with each
	header and recursive call of $\qreva$:
	\begin{enumerate}
		\item $\qreva(x,\sigma_1)$ unified with $\qreva(\nil,y)$ gives the mapping $\{\sigma_0\mapsto\nil\}$.
		\item $\qreva(x,\sigma_1)$ unified with $\qreva(\cons(u,v),y)$ gives $\{\sigma_0\mapsto\cons(u,v)\}$
		\item To obtain the hypothesis of the second case, we first apply the unifier on its recursive call: $\qreva(v, \cons(u,\sigma_1))$. The mapping for the corresponding hypothesis is then $\{\sigma_0\mapsto v\}$.
	\end{enumerate}
	We use the mappings to create an induction formula: each mapping defines what to replace in the corresponding cases and induction hypotheses. Moreover, we add an induction conclusion matching the induction terms:
	\begin{align}
    \nonumber	&\Big(\qreva(\nil,\sigma_1)=\append(\rev(\nil),\sigma_1)\land\\
	\begin{split}\nonumber&\forall u,v.\big(\qreva(v,\sigma_1)=\append(\rev(v),\sigma_1)\rightarrow\\
	&\qreva(\cons(u,v),\sigma_1)=\append(\rev(\cons(u,v)),\sigma_1)\big)\Big)\end{split}\\
    \nonumber&\rightarrow \forall x.\qreva(x,\sigma_1)=\append(\rev(x),\sigma_1)
	\end{align}
\end{example}

The above method -- when used on each predicate and function term in a literal -- gives "matching" induction formulas in a sense that in each case of an induction formula by definition at least the term this formula was generated from will be an instance of the corresponding function/predicate definition.

The method can be improved in two regards: first, we can recursively mark terms in a literal in active positions and only generate formulas from those, since all others will get stuck at some point. Second, we can create terms to generate from based on subterms in active arguments.

For example the following literal contains two terms that can generate induction formulas:
$$\neg\fleq(\sigma_0,\add(\sigma_1,\sigma_0))$$
The first one gives induction terms $\sigma_0$ and $\add(\sigma_1,\sigma_0)$, the second $\sigma_1$, whereas we need one where we induct on $\sigma_0$ and $\sigma_1$ simultaneously, to match the recursive case of $\fleq$ after simplifying with $\add$. But when looking at the $\fleq$ term, instead of only taking the $\add$ term as the second argument, we look inside its active arguments and take $\sigma_1$ also (essentially generating from term $\fleq(\sigma_0, \sigma_1)$).

More generally, when considering a term $\mathtt{f}(t_1,...,t_n)$, we take all subterms in its active argument positions $t_i$ with the same sort as $t_i$, and take all combinations (leaving non-active arguments).
\subsection{Strengthening the hypotheses}
In Example \ref{ex:3}, after clausification and rewriting with function definitions, the base case is solved, but we are left with the following two unit clauses (the step case conclusion and hypothesis):
$$\qreva(\sigma_2,\sigma_1)=\append(\rev(\sigma_2),\sigma_1)$$
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))\neq\append(\append(\rev(\sigma_2),\cons(\sigma_3,\nil)),\sigma_1)$$
An easy solution for this is to use a \textit{strengthened hypothesis}, where we replace $\sigma_1$ with a universally quantified variable, so that the left-hand sides will match:
$$\qreva(\sigma_2,z)=\append(\rev(\sigma_2),z)$$
Yet, this "too strong" hypothesis can backfire in many ways: not only does it burden the solver by more potential rewrites but the prover may even demodulate the wrong side of the step conclusion after which the proof is ultimately stuck:
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))\neq\append(\qreva(\sigma_2,\cons(\sigma_3,\nil),\sigma_1))$$
Our proposed solution is to use accumulator argument positions to gives us hints at possible non-trivial hypotheses. In Example \ref{ex:3}, unifying with the recursive call gives $\qreva(v, \cons(u,\sigma_1))$, which means we can replace $\sigma_1$ -- after Skolemizing $\cons(u,\sigma_1)$ -- with $\cons(\sigma_3,\sigma_1)$:
$$\qreva(\sigma_2,\cons(\sigma_3,\sigma_1))=\append(\rev(\sigma_2),\cons(\sigma_3,\sigma_1))$$
The left-hand sides now match exactly, so applying the hypothesis gives:
$$\append(\rev(\sigma_2),\cons(\sigma_3,\sigma_1))\neq\append(\append(\rev(\sigma_2),\cons(\sigma_3,\nil)),\sigma_1)$$

\subsection{Generalizations}
As described in \cite{vampiregeneralization}, inducting on all occurrences of an induction term may lead to a failed proof even if the case distinction was the right one. Inspired by \cite{cruanes}, we devised a heuristic that takes \textit{all active occurrences} of an induction term. So for example, we generalize the literal $\forall x.\fleq(x,\add(x,x))$ to $\forall x,z.\fleq(z,\add(z,x))$.

But sometimes, e.g. in $\forall x.\double(x) = \add(x,x)$, we have to take all occurrences including the last, non-active one. We therefore, instead of trying to guess the right one, try both active and all occurrences. So we generalize to $\forall x,z.\double(z) = \add(z,x)$ and $\forall z.\double(z) = \add(z,z)$ as well.

