% !TeX root = ./paper.tex

Interpreted functions are often axiomatized in a definitional form, meaning that given these axioms for a well-founded function $f$, any occurrence of $f$ in a ground function term can be completely eliminated. In this paper, we consider well-founded (terminating) functions that are \textit{not mutually-recursive}. Although handling \textit{recursive} functions needs a bit of precaution because expanding any non-ground recursive function term into its definition may lead to a rewrite loop, we treat non-recursive functions the same since they can be thought of as functions that contain only base cases.
\subsection{Generating induction formulas from function definitions}\label{sec:generating}
A function definition is a set of axioms of the form
$$F\rightarrow f(s_1,...,s_n):=t$$
as presented in Section \ref{sec:preliminaries}. For now, we treat the detection of such function definitions as a black box and address this issue later. An argument position $1\le i\le n$ of $f$ is an \textit{active argument position} if there is an axiom like above of $f$ s.t. for some $f(t_1,...,t_n)\trianglelefteq t$ and $s_i\neq t_i$. Given a literal $L$, we mark its \textit{active subterms} inductively as follows:
\begin{itemize}
	\item if $L$ is an equality $l=r$, then $l$ and $r$ are active subterms
	\item for an active recursive predicate/function subterm $f(s_1,...,s_n)$ of $L$ with active argument positions $I$, all $s_i$ with $i\in I$ are active subterms of $L$
	\item for an active non-recursive predicate/function subterm $f(s_1,...,s_n)$ of $L$, all $s_i$, $1\le i\le n$ are active subterms of $L$
	\item if $c(t_1,...,t_m)$ is an active constructor subterm of $L$ of type $\tau$, all $t_j$ with type $\tau$ are active subterms of $L$
\end{itemize}
\todo{should we exclude non-recursive function terms here? it is sometimes good to induct on them (which is just a case distinction) but otherwise it can be confusing to introduce this here}

Every active subterm of a literal is a candidate for induction since replacing these terms with a case distinction of constructor terms leads to simplifiable literals that we can possible solve. Functions can recurse on multiple arguments, so instead of creating an induction formula for each active subterm, we look at active function subterms with non-empty active argument position sets and create induction formulas from their active subterms.

In order to create an induction formula, we create (1) a case distinction on the induction terms that is exhaustive and non-overlapping (and can contain guard conditions) and (2) induction hypotheses for the step cases. For both, we substitute the induction terms with the terms from the corresponding case/hypothesis into the original literal. For the case distinction, we use the function axioms which are by assumption well-defined.

Sometimes function terms contain only complex terms in their active argument positions and generalizing over them does not always lead to a proof. E.g. in $s\leq t+s$, both arguments of the outermost function $\leq$ are active but only the first argument of $+$ is active, therefore it is essential to induct on both $s$ and $t$. The other possibility is to induct on $t+s$ from the second position which would render the original true literal false.

To solve this issue, we create tuples of possible induction terms for each such function term by taking every combination of active subterms of $s_i$ for all $i$ in the set of active argument positions. In the above example, this yields $(s,t)$ and $(s,t+s)$ as possible induction term tuples. We can create from them and the axioms of $\leq$ the following case distinctions by substituting each tuple element with the corresponding argument in the function's axioms in the literal $s\leq t+s$:
$$\begin{aligned}
&\forall x.\textcolor{blue}{0}\leq \textcolor{red}{x}:=\top\quad&\Rightarrow\quad&\textcolor{blue}{0}\leq \textcolor{red}{x}+\textcolor{blue}{0}\quad&(L_1)\\
&\forall x.\textcolor{blue}{\suc(x)}\leq \textcolor{red}{0}:=\bot\quad&\Rightarrow\quad&\textcolor{blue}{\suc(x)}\leq \textcolor{red}{0}+\textcolor{blue}{\suc(x)}\quad&(L_2)\\
&\forall x,y.\textcolor{blue}{\suc(x)}\leq \textcolor{red}{\suc(y)}:=x\leq y\quad&\Rightarrow\quad&\textcolor{blue}{\suc(x)}\leq \textcolor{red}{\suc(y)}+\textcolor{blue}{\suc(x)}\quad&(L_3)
\end{aligned}$$
The next step is to add induction hypotheses where possible -- an axiom $F\rightarrow f(s_1,...,s_n):=t$ gives induction hypotheses for the corresponding case in the case distinction if there are recursive calls in $t$. Each such recursive call gives rise to a new literal the same way as in the case distinctions. For $\leq$, only the last case has a recursive call:
$$\begin{aligned}
&\forall x,y.\suc(x)\leq \suc(y):=\textcolor{blue}{x}\leq \textcolor{red}{y}\quad&\Rightarrow\quad&\textcolor{blue}{x}\leq \textcolor{red}{y}+\textcolor{blue}{x}\quad&(L_{31})
\end{aligned}$$

The obtained literals are then conjuncted to get the induction formula antecedent. The induction hypotheses for each case are conjuncted then added as antecedent to the literal of that case. We add a conclusion literal to the final formula where each induction term is replaced with a fresh variable:
$$\begin{pmatrix}\forall x.L_1\land\forall x.L_2\land\forall x,y.(L_{31}\rightarrow L_3)\end{pmatrix}\rightarrow \forall u,v.u\leq v+u$$

The substitutions we apply to the literal may not be confluent or well-defined. For example, a literal $r\leq r+r$ would require us to substitute both $0$ and $\suc(x)$ for $r$ in the second case of $\leq$. The two terms cannot be unified so they would result in a literal we cannot solve and we discard this case. Hypotheses can also be discarded because the substitutions are inconsistent. Losing hypotheses this way is not an issue, but losing a case from the induction formula can result in unsoundness. \todo{state that case distinctions are well-defined even when we throw away cases?}

\subsection{Containment and union of induction formulas}
Even though there may be multiple induction formulas used for the proof of an inductive goal, the process described in Section \ref{sec:generating} can create many similar or redundant ones. Therefore an important step is to discard the unusable ones and combine the rest if possible. Looking at the Example \ref{ex:1} once again, from the literal $\neg\even(\sigma_0+\sigma_1)$ we can create two induction formulas with non-complex induction terms. One is generated from $\even(\sigma_0+\sigma_1)$:
\begin{equation}\label{eq:even1}\begin{pmatrix}\even(0+\sigma_1)\land\even(\suc(0)+\sigma_1)\land\\
\forall z.(\even(z+\sigma_1)\rightarrow\even(\suc(\suc(z))+\sigma_1))\end{pmatrix}\rightarrow \forall u.\even(u+\sigma_1)\end{equation}
The other is given by $\sigma_0+\sigma_1$:
\begin{equation}\label{eq:even2}\begin{pmatrix}\even(0+\sigma_1)\land\forall x.(\even(x+\sigma_1)\rightarrow\even(\suc(x)+\sigma_1))\end{pmatrix}\rightarrow \forall z.\even(z+\sigma_1)\end{equation}
Practically, trying \eqref{eq:even2} is a waste of resources as we have already seen in Section \ref{sec:motivating} so we better off discarding it. There are very simple approaches in the literature on which one can base this decision. E.g. \textsc{ACL2} would discard it because the step case of \eqref{eq:even1} is in the \textit{transitive closure} of that of \eqref{eq:even2}. In terms of well-founded relations, \eqref{eq:even2} is based on the relation $x\prec\suc(x)$ and applying this twice gives us $x\prec\cdot\prec\suc(\suc(x))$, that is, the relation for \eqref{eq:even1}.

The reason this works is only incidental -- although the case distinction of $+$ is more general than that of $\even$ and therefore every term in the case distinction of $\even$ will match a function definition of +, the induction hypothesis of the two are completely unrelated and therefore discarding one of them is like flipping a coin before the proof without knowing which one will be needed.

In order not to lose useful structure from the generated induction formulas, our goals are the following: when discarding or combining induction formulas (1) more special case distinctions must be preserved so that all considered function definitions are matched and (2) all induction hypotheses must be preserved since a priori we do not know which ones will be used.

For two induction formulas $F_1$ and $F_2$ with identical case distinctions, $F_1$ \textit{contains} $F_2$ if for each case, the set of induction hypotheses of the case in $F_1$ is a superset of that of $F_2$. If an induction formula is contained by another, we can safely discard it since its case distinction and induction hypotheses can be found in the second.
\begin{example}
	\todo{add example}
\end{example}

If two induction formulas do not contain each other, we can either use them separately or use their \textit{union} instead \cite{combining}. The union of two induction formulas provides a case distinction with all cases from the original ones while supplying the necessary induction hypotheses. We can compute the union with the following two approaches:
\begin{enumerate}
	\item We can think of the two in terms of well-founded orders and for each pair of subrelations from the first and the second, we compute their intersections. Then, we check whether any subrelation has cases left "outside" the intersections. Finally, we convert this union of orders back to a formula by adding the remaining cases, i.e. the base cases.
	\item Otherwise, we can simply intersect every case of the two induction formulas putting together their induction hypotheses.
\end{enumerate}
\begin{example}
	Let us look at the case distinction of formulas \eqref{eq:even1} and \eqref{eq:even2} from our running Example \ref{ex:1}.

	\textit{Approach 1.} The formulas give relations $z\prec\suc(\suc(z))$ and $x\prec\suc(x)$, respectively. The intersection of the two is a relation $z,\suc(z)\prec\suc(\suc(z))$. This can be seen as letting the more general $\suc(x)$ to match only its $\suc(\suc(z))$ instance and putting together the related terms $z$ and $x$, but since $\suc(x)$ was specialized to $\suc(\suc(z))$ we also need to specialize $x$ $\suc(z)$.

	Then, we need to check what remains of the original subrelations apart from the intersection. While $z\prec\suc(\suc(z))$ was used as-is in the intersection, so it is covered, an instance of $x\prec\suc(x)$ was used, thus the remaining instance $0\prec\suc(0)$ is added.

	Converting this back to an induction formula, to make sure the case distinction is complete, we add base case 0 which is not covered by $\suc(0)$ nor $\suc(\suc(z))$.

	\textit{Approach 2.} We take intersections of each case from \eqref{eq:even1} and \eqref{eq:even2} pairwise:
	\begin{itemize}
		\item $0$ and $0$ overlap in $0$. Both are base cases so this results in a base case.
		\item $0$ and $\suc(x)$ do not overlap.
		\item $\suc(0)$ and $0$ do not overlap.
		\item $\suc(0)$ and $\suc(x)$ overlap in $\suc(0)$. The second is a recursive case, so we add the induction hypothesis $0$ which is $x$ specialized to match the overlap.
		\item $\suc(\suc(z))$ and $0$ do not overlap.
		\item $\suc(\suc(z))$ and $\suc(x)$ overlap. Both are recursive cases, so we add the two induction hypotheses, specialized where needed ($x$ is specialized to $\suc(z)$).
	\end{itemize}

	Both approaches give the induction formula:
	\begin{equation}\label{eq:even}\begin{pmatrix}\even(0+\sigma_1)\land(\even(0+\sigma_1)\rightarrow\even(\suc(0)+\sigma_1))\land\\
	\forall z.((\even(z+\sigma_1)\land\even(\suc(z)+\sigma_1))\rightarrow\even(\suc(\suc(z))+\sigma_1))\end{pmatrix}\rightarrow \forall u.\even(u+\sigma_1)\end{equation}
\end{example}

We note here that it is enough to check pairwise intersections only because the induction formulas (and the functions they are generated from) are by assumption well-defined, so each case distinction is non-overlapping and exhaustive.

One of the advantages of taking the union is that by definition it is guaranteed that each case matches exactly one function axiom for each of the original function terms and the necessary induction hypotheses are also always present. The disadvantages are that it may not be well-founded and that it can create very large induction formulas. It is also not clear when to use it. There are situations when two induction formulas use completely different induction terms. For example, the commutativity of +
$$\forall x,y.x+y=y+x$$
can be solved by first inducting on $x$ and then on $y$ or vice versa -- the order is irrelevant. However, in general, depending on the order of simplifications and the axioms used for each function, inducting sequentially on multiple terms can lead to different results.

\todo{Give some heuristics on when to use the union.}

\subsection{Well-foundedness and well-definedness}
So far we assumed that every function we are provided with is well-founded and well-defined. Functions that fail to meet this requirement are potential sources of unsoundness. Well-foundedness must be also checked when creating the union of two induction formulas.

We chose easy-to-check sufficient conditions for both. We base our well-foundedness check on a lexicographic order on the active argument positions of each function and use the subterm relation as elementary property. This can be easily checked with e.g. constructor-style input functions where arguments of inductive sorts on the left-hand side of a function definition are either variables or term algebra constructors. A common example for this is the Ackermann function given by:
$$\begin{aligned}\forall y. \ack(0,y)&:=\suc(y)\\
\forall x.\ack(\suc(x),0)&:=\ack(x,\suc(0))\\
\forall x,y.\ack(\suc(x),\suc(y))&:=\ack(x,\ack(\suc(x),y))\end{aligned}$$
Any function term stemming from a function that is not well-founded is ignored while generating induction formulas.

After generating the union of two induction formulas, we check whether each case - recursive call pair obeys a lexicographic order and discard the union if not.

For well-definedness, we distinguish \textit{under-definedness} and \textit{over-definedness}. The former can lead to missing false cases, thus introducing unsoundness but it can be easily mitigated by adding those missing cases. The latter is a bit more complicated: an induction formula with overlapping cases is not necessarily unsound but it can lead to ill-constructed case distinctions for the union. \todo{anything to add here?}

\subsection{Induction hypothesis strengthening}
Sometimes an inductive step fails because the required hypothesis only partially matches the conclusion after simplification. This can be resolved in some cases by adding more related pairs to the subrelation in the corresponding well-founded order.

As discussed previously, a suitable lexicographic order establishes the well-foundedness of any function. This order determines which induction terms are needed for the current subrelation to be decreasing. Any other induction terms in the relation can be strengthened to relate all possible pairs by replacing their terms in the hypothesis with fresh variables. Other than that, non-induction terms -- which can be thought of as induction terms implicitly stated and not needed for the well-foundedness -- can be also strengthened this way.

\begin{example}
	An induction formula on literal $L[s][t][r]$ based on the function $\ack$ with induction terms $s$ and $t$ and non-induction term $r$ is the following:
	$$\begin{pmatrix}\forall y.L[0][y][r]\land \forall x.(L[x]\textcolor{red}{[\suc(0)][r]}\rightarrow L[\suc(x)][0][r])\\
	\forall x,y.((L[x]\textcolor{red}{[\ack(\suc(x),y)][r]}\land L[\suc(x)][y]\textcolor{red}{[r]})\rightarrow L[\suc(x)][\suc(y)][r])\end{pmatrix}\rightarrow \forall u,v.L[u][v][r]$$
	We marked the occurrences in each hypothesis with \textcolor{red}{red} that are not needed for the well-foundedness. These can be replaced with universally quantified fresh variables:
	$$\begin{pmatrix}\forall y.L[0][y][r]\land \forall x.(\forall z_0,z_1.L[x]\textcolor{red}{[z_0][z_1]}\rightarrow L[\suc(x)][0][r])\\
	\forall x,y.((\forall z_2,z_3.L[x]\textcolor{red}{[z_2][z_3]}\land \forall z_4.L[\suc(x)][y]\textcolor{red}{[z_4]})\rightarrow L[\suc(x)][\suc(y)][r])\end{pmatrix}\rightarrow \forall u,v.L[u][v][r]$$
\end{example}

\subsection{Generalizing over occurrences and complex terms}
\todo{maybe shorten this to referencing the generalization paper and add that we always include all active term occurrences}
A useful general proof technique is \textit{generalizing formulas}, i.e. proving a more general statement. This is usually done to obtain shorter proofs or get rid of some complexity which prevents us from getting a proof in the first place.
\begin{example}
	The following statement cannot be solved by simply inducting on $x$:
	$$\forall x. x\leq x + x$$
	After simplifying the inductive step case
	$$\forall x. x\leq x + x \rightarrow \suc(x)\leq\suc(x)+\suc(x)$$
	the conclusion and the hypothesis do not match:
	$$\forall x. x\leq x + x \rightarrow x\leq x+\suc(x)$$
	We can generalize the original statement to leave out the problematic third occurrence of $x$ and induct on $z$ instead:
	$$\forall x,z. z\leq z + x$$
	Another example is the following, where simply inducting on $z$ leads to a non-theorem in the inductive step:
	$$\forall y,z.\rev(\rev(z)\append\cons(y, \nil)) = \cons(y,\rev(\rev(z)))$$
	The solution is to generalize over $\rev(z)$ to get a statement that is easier to prove:
	$$\forall x,y.\rev(x\append\cons(y, \nil)) = \cons(y,\rev(x))$$
\end{example}
It is usually beneficial to generalize any formula before inducting on it. However, generalizing over all possible occurrences of any subterm of a formula gives a large number of induction formulas, most of which is not provable. Therefore certain heuristics are needed to reduce the number of generated induction formulas. One is based on the observation that non-active subterm occurrences -- when replaced with some constructor term in e.g. an inductive step conclusion -- remain fixed and cannot be eliminated.

However, sometimes they are needed to preserve validity of the property we are trying to prove. On the other hand, active subterm occurrences are usually needed to prove the property. So our heuristics are mostly good-to-go if they generalize over the active occurrences and try out all combinations of non-active ones.

For a complex subterm, our heuristic is to generalize over it if it has at least one active occurrence. The individual occurrences are then generalized according to the rules presented above.