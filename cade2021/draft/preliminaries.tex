% !TeX root = ./paper.tex

We assume familiarity with \textit{standard multi-sorted first-order logic with equality}. Functions are denoted with $f$, $g$, $h$, predicates with $p$, $q$, $r$ and variables with $x$, $y$, $z$, $u$, $v$, $w$, possibly with indices. We reserve the notation $\sigma$, $\sigma_0$, $\sigma_1$, etc. for Skolem constants. A term is \textit{ground} if it contains no variables. The notation $\overline{x}$ and $\overline{t}$ means tuples of variables and terms, respectively.

We use the standard logical connectives $\neg$, $\lor$, $\land$, $\rightarrow$ and $\leftrightarrow$ and quantifiers $\forall$ and $\exists$. \textit{Atoms} are built inductively from terms and predicate symbols. Atoms and their negations are called \textit{literals}. For a literal $l$, we use the notation $\overline{l}$ to denote its opposite sign literal. \textit{Formulas} are built from connectives and atoms.

Additionally, a disjunction of literals is a \textit{clause}. We reserve the symbol $\square$ for the \textit{empty clause} which is logically equivalent to $\bot$. We call every term, literal, clause or formula an \textit{expression}. We use the notation $s\trianglelefteq t$ to denote that $s$ is a \textit{subterm} of $t$ and $s\triangleleft t$ if $s$ is a \textit{proper subterm} of $t$.

We may use the words \textit{sort} and \textit{type} interchangeably. We distinguish special sorts called \textit{inductive sorts}, function symbols for inductive sorts called \textit{constructors} and \textit{destructors}. We require that the signature contains at least one constant constructor symbol for every inductive type. Such a symbol is called a \textit{base constructor}, while non-constant ones are called \textit{recursive constructors}. We call the ground terms built from the constructor symbols of a sort its \textit{term algebra}. Semantically, each $n$-ary constructor $c$ has $n$ corresponding destructors $d_1,...,d_n$. For any constructor term $c(t_1,...,t_n)$ with root symbol $c$, the following holds:
$$\forall 1\le i\le n. d_i(c(t_1,...,t_n))=t_i$$
Moreover, we usually axiomatise every term algebra with the \textit{injectivity}, \textit{distinctness}, \textit{exhaustiveness} and \textit{acyclicity} axioms. The inductive types we use in this paper are:
$$\begin{aligned}\nat&:=0 &&\mid \suc(\pre(\nat))\\
\lst&:=\nil&&\mid\cons(\head(\nat),\tail(\lst))\\
\btree&:=\bnil &&\mid \bnode(\bleft(\btree),\bval(\nat),\bright(\btree))\end{aligned}$$

An \textit{interpreted symbol} is a function or predicate whose meaning is defined through axioms, e.g. $=$ is an interpreted symbol in first-order logic with equality. All other symbols are called \textit{uninterpreted}. We distinguish \textit{function/predicate definitions} from regular axioms. These define a branch of computation for a function/predicate. Such axiom is denoted by marking exactly one equality literal in it with $:=$ such as $F\rightarrow l:=r$ which means that the orientation of this equality is fixed as left-to-right, $l$ is a function header and $r$ is a function definition, $F$ is the guard condition for this branch. We abuse this notation for predicate definitions where $:=$ can be replaced with a $\leftrightarrow$.

A notation we use is $E[s]$ meaning there is one (or more) distinguished occurrence(s) of the term $s$ in $E$. $E[t]$ then means that these occurrences are changed to a term $t$. 

A relation $R$ on a set $A$ is a \textit{simplification ordering} if:
\begin{itemize}
	\item it is \textit{stable under substitutions}\index{stable relation under substitutions}, i.e. $a\ R\ b$ implies $a\theta\ R\ b\theta$ for all $a, b\in A$ and substitutions $\theta$
	\item it is \textit{monotonic}\index{monotonic relation}, i.e. $a\ R\ b$ implies $s[a]\ R\ s[b]$ for all $a,b,s\in A$
	\item it has the \textit{subterm property}, i.e. $a\ \triangleleft\ b$ implies $a\ R\ b$
\end{itemize}
\subsection{Saturation-based proof search}
Given a set of input formulas $C$ in clausal form, the set of all derivable clauses using an inference system from the set $C$ is called the \textit{closure of $F$} w.r.t. the system. If the closure contains $\square$, the original set $C$ is unsatisfiable, otherwise it is satisfiable. The process of computing the closure is called \textit{saturation}. In practice more subtle notions are needed to tackle this problem, the first one is \textit{saturation up to redundancy}. A clause $C$ is \textit{redundant} w.r.t a set of clauses $S$ if some subset of $S$ of clauses smaller than $C$ w.r.t $\succ$ logically imply $C$. An inference system is usually equipped with \textit{simplification and deletion rules} to get rid of redundant clauses. Second, selection methods are used which control the order in which the inferences are applied. For a more detailed discussion on saturation algorithms see \cite{cav13}.

We use the \textit{superposition calculus} as the inference system in this paper. It works on sets of clauses -- we treat the conversion to \textit{clausal normal form} (or CNF) as a black box \cite{vcnf} and denote the conversion of a formula $F$ to its conjunctive normal form with $\mathtt{cnf}(F)$. The superposition calculus is \textit{sound} and \textit{refutationally complete}. A \textit{refutation} is a derivation of $\bot$. Refutational completeness means for any unsatisfiable formula set, we can derive the empty clause. Therefore, with superposition we usually negate our input conjecture and try to refute it which, if successful, means the original conjecture is valid.

For the completeness a simplification term ordering $\succ$ of terms is needed (e.g. KBO, LPO) which is extended to literals and clauses with the multiset-extension. We will abuse notation and use the same symbol $\succ$ to denote the original ordering and its extensions.